{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LCS Demo 2\n",
    "\n",
    "**LCS Workshop- Educational LCS - eLCS**\n",
    "\n",
    "Outcome: *Learn the concept and use of Learning Classifier Systems *(*LCSs*)\n",
    "\n",
    "Instructors: [Dr Ryan Urbanowicz](http://www.ryanurbanowicz.com/), [Dr Will Browne](http://ecs.victoria.ac.nz/Main/WillBrowne) And [Dr Karthik Kuber](http://kkuber.mysite.syr.edu/),\n",
    "\n",
    "The following topics will be covered in a series of hands-on exercises and demonstrations:\n",
    "1. LCS in a Nutshell \n",
    "2. LCS Concepts \n",
    "3. LCS Functional Cycle \n",
    "4. LCS Adaptability \n",
    "5. LCS Applications (toy and real problems) \n",
    "\n",
    "<p style=\"color:red;\">Welcome to the Educational Learning Classifier System (eLCS).</p> \n",
    "It has the core elements of the functionality that help define the concept of LCSs. It’s the same family as the fully featured ExSTraCS system, so it is easy to transfer to a state-of-the-art LCS from this shallow learning curve.\n",
    "\n",
    "eLCS complements the forthcoming *Textbook on Learning Classifier Systems*. Each demo is paired with one of the chapters in the textbook. Therefore, there are 5 different versions of an educational learning classiﬁer system (eLCS), as relevant functionality (code) is added to eLCS at each stage. This builds up the eLCS algorithm in its entirety from Demo 1 through to 5. Demo 6 showcases how ExSTraCS may be applied to a real-world data mining example, i.e. large scale bioinformatics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Demo 1 Understanding of what an LCS is attempting – how does it classify the training data?\n",
    "- **Demo 2 Matching and Covering**\n",
    "- Demo 3 Prediction, Rule Population Evaluations, GA Rule Discovery and Parental Selection\n",
    "- Demo 4 Deletion and Niche GA + Subsumption\n",
    "- Demo 5 Complete eLCS applied to a complex (toy) problem\n",
    "- Bonus Demo 6 ExSTraCS applied to a real-world data mining example \n",
    "\n",
    "All code is in Python. This newest version is coded in Python 3.4. Here it is to be run in the Jupyter platform (http://jupyter.org/), as it supports interactive data science.\n",
    "\n",
    "Each demo version only includes the minimum code needed to perform the functions they were designed for. This way users can start by examining the simplest version of the code and progress onwards. The demo exercises are to implement several functions in eLCS and view results in spreadsheet, text ﬁle or Python based graphics (preferable).\n",
    "\n",
    "## Set-up and introduction to Jupyter\n",
    "\n",
    "Please see http://jupyter.org/ on how to set-up Jupyter with Python 3.\n",
    "Please download eLCS_1.ipynb, … , eLCS_5.ipynb from Github \n",
    "Please see earlier demos for hide_code and initial introductions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Name:        eLCS_Run.py\n",
    " - Authors:     Ryan Urbanowicz - Written at Dartmouth College, Hanover, NH, USA\n",
    " - Contact:     ryan.j.urbanowicz@darmouth.edu\n",
    " - Created:     November 1, 2013\n",
    " - Description: To run e-LCS, run this module.  A properly formatted configuration file, including all run parameters must be included with the path to that file given below.  In this example, the configuration file has been included locally, so only the file name is required.\n",
    "             \n",
    "--------------------------------------------------------------------------------------------------------------------------------\n",
    "eLCS: Educational Learning Classifier System - A basic LCS coded for educational purposes.  This LCS algorithm uses supervised learning, and thus is most \n",
    "similar to \"UCS\", an LCS algorithm published by Ester Bernado-Mansilla and Josep Garrell-Guiu (2003) which in turn is based heavily on \"XCS\", an LCS \n",
    "algorithm published by Stewart Wilson (1995).  \n",
    "\n",
    "Copyright (C) 2013 Ryan Urbanowicz \n",
    "This program is free software; you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the \n",
    "Free Software Foundation; either version 3 of the License, or (at your option) any later version.\n",
    "\n",
    "This program is distributed in the hope that it will be useful but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABLILITY \n",
    "or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.\n",
    "\n",
    "You should have received a copy of the GNU General Public License along with this program; if not, write to the Free Software Foundation, \n",
    "Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2 LCS Concepts: Matching and Covering**\n",
    "**2.1. Demo 2** (Code Demo: Matching and Covering) This ﬁrst implementation of eLCS is extremely basic. Each progressive version  includes the code to set run parameters, as well as code to manage an ofﬂine environment (load and manage a ﬁnite dataset). This ﬁrst version of eLCS, pretty much only includes the framework of an LCS, i.e. the code to form a population, a match set, a correct set (found in Classiﬁer Set cell), and to construct a classiﬁer (found in Classiﬁer Class cell). Because of their link we introduce both matching and covering together in this initial version. This version can be run from scratch, in which case covering will initially add rules to the population until some randomly generated set of covered rules, covers all instances in the dataset. The code is set to initially run from scratch for 64 iterations (i.e. one cycle through the dataset).\n",
    "\n",
    "**2.2. Demo 2+ ** (*for those who finish 2 early*). Alternatively this version can reboot, i.e. load, an existing rule population, to demonstrate matching more completely. To reboot a population, go into the conﬁguration ﬁle and change doPopulationReboot from 0 to 1. In this case, covering will not kick in as all instances should already be covered. Instead, all matching rules will be displayed. Restarting the kernal and deleting 'ExampleRun_eLCS_LearnTrack.txt' before running will produce a clearer figure.\n",
    "\n",
    "We have encoded this version to use print statements to show what’s going on in the algorithm regarding covering and matching. Each iteration, the dataset instance is displayed, followed by any matching rules, as well as any covered rules if covering is activated. The iteration ends with a print out of the iteration number, the current population size and the average rule generality in the population.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "hideCode": true
   },
   "outputs": [],
   "source": [
    "# Import useful prewritten code from Python libraries\n",
    "import random\n",
    "import copy\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "Configure the parameters, usually from a txt file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "hideCode": true
   },
   "outputs": [],
   "source": [
    "###### Configuration File (eLCS)\n",
    "#     In the pure Python eLCS the list  'parameters[parameter] = value #Store parameters in a dictionary' is used \n",
    "######--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "###### Major Run Parameters - Essential to be set correctly for a successful run of the algorithm\n",
    "######--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "trainFile=\"6Multiplexer_Data_Complete.txt\"\t\t# Path/FileName of training dataset\n",
    "testFile='None'\t\t\t\t\t\t\t\t\t# Path/FileName of testing dataset.  If no testing data available or desired, put 'None'.  \n",
    "outFileName=\"ExampleRun\"\t\t\t\t\t\t\t# Path/NewName for new algorithm output files. Note: Do not give a file extension, this is done automatically.\n",
    "learningIterations=64\t\t\t\t\t\t# Specify complete algorithm evaluation checkpoints and maximum number of learning iterations (e.g. 1000.2000.5000 = A maximum of 5000 learning iterations with evaluations at 1000, 2000, and 5000 iterations)\n",
    "N=1000\t\t\t\t\t\t\t\t\t\t\t# Maximum size of the rule population (a.k.a. Micro-classifier population size, where N is the sum of the classifier numerosities in the population)\n",
    "p_spec=0.5\t\t\t\t\t\t\t\t\t\t# The probability of specifying an attribute when covering. (1-p_spec = the probability of adding '#' in ternary rule representations). Greater numbers of attributes in a dataset will require lower values of p_spec.\n",
    "\n",
    "######--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "###### Logistical Run Parameters\n",
    "######--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "randomSeed=False\t\t\t\t\t\t\t\t# Set a constant random seed value to some integer (in order to obtain reproducible results). Put 'False' if none (for pseudo-random algorithm runs).\n",
    "labelInstanceID=\"InstanceID\"\t\t\t\t\t\t# Label for the data column header containing instance ID's.  If included label not found, algorithm assumes that no instance ID's were included.\n",
    "labelPhenotype=\"Class\"\t\t\t\t\t\t\t# Label for the data column header containing the phenotype label. (Typically 'Class' for case/control datasets)\n",
    "labelMissingData=\"NA\"\t\t\t\t\t\t\t\t# Label used for any missing data in the data set.\n",
    "discreteAttributeLimit=10\t\t\t\t\t\t# The maximum number of attribute states allowed before an attribute or phenotype is considered to be continuous (Set this value >= the number of states for any discrete attribute or phenotype in their dataset).\n",
    "trackingFrequency=1\t\t\t\t\t\t\t\t# Specifies the number of iterations before each estimated learning progress report by the algorithm ('0' = report progress every epoch, i.e. every pass through all instances in the training data).\n",
    "\n",
    "######--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "###### Supervised Learning Parameters - Generally just use default values.\n",
    "######--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "nu=5\t\t\t\t\t\t\t\t\t\t\t# (v) Power parameter used to determine the importance of high accuracy when calculating fitness. (typically set to 5, recommended setting of 1 in noisy data)\n",
    "init_fit=0.01\t\t\t\t\t\t\t\t\t# The initial fitness for a new classifier. (typically very small, approaching but not equal to zero)\n",
    "\n",
    "######--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "###### PopulationReboot - An option to begin e-LCS learning from an existing, saved rule population. Note that the training data is re-shuffled during a reboot.\n",
    "######--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "doPopulationReboot=0\t\t\t\t\t\t\t# Start eLCS from an existing rule population? (1 is True, 0 is False).\n",
    "popRebootPath=\"ExampleRun_eLCS_5000\"\t\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the constants that control the evolutionary process [i.e. the 'cons' object from Constants class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "hideCode": true
   },
   "outputs": [],
   "source": [
    "class Constants:\n",
    "    def setConstants(self):\n",
    "        \"\"\" Takes the parameters parsed as a dictionary from eLCS_ConfigParser and saves them as global constants. \"\"\"\n",
    "        \n",
    "        # Major Run Parameters -----------------------------------------------------------------------------------------\n",
    "        self.trainFile = trainFile # par['trainFile']                                       #Saved as text\n",
    "        self.testFile = testFile #par['testFile']                                         #Saved as text\n",
    "        self.originalOutFileName = outFileName #str(par['outFileName'])                      #Saved as text\n",
    "        self.outFileName = outFileName +'_eLCS'  #str(par['outFileName'])+'_eLCS'                  #Saved as text\n",
    "        self.learningIterations = learningIterations #par['learningIterations']                     #Saved as text\n",
    "        self.N = N #int(par['N'])                                                  #Saved as integer\n",
    "        self.p_spec = p_spec # float(par['p_spec'])                                      #Saved as float\n",
    "        \n",
    "        # Logistical Run Parameters ------------------------------------------------------------------------------------\n",
    "       # if par['randomSeed'] == 'False' or par['randomSeed'] == 'false':\n",
    "        if randomSeed == False:\n",
    "            self.useSeed = False                                                #Saved as Boolean\n",
    "        else:\n",
    "            self.useSeed = True                                                 #Saved as Boolean\n",
    "            self.randomSeed = randomSeed #int(par['randomSeed'])                #Saved as integer\n",
    "            \n",
    "        self.labelInstanceID = labelInstanceID  #par['labelInstanceID']                           #Saved as text\n",
    "        self.labelPhenotype = labelPhenotype # par['labelPhenotype']                             #Saved as text\n",
    "        self.labelMissingData = labelMissingData  #par['labelMissingData']                         #Saved as text\n",
    "        self.discreteAttributeLimit = discreteAttributeLimit # int(par['discreteAttributeLimit'])        #Saved as integer\n",
    "        self.trackingFrequency = trackingFrequency  #int(par['trackingFrequency'])                  #Saved as integer\n",
    "        \n",
    "        # Supervised Learning Parameters -------------------------------------------------------------------------------\n",
    "        self.nu = nu #int(par['nu'])                                                #Saved as integer\n",
    "        self.init_fit = init_fit #float(par['init_fit'])                                  #Saved as float\n",
    "\n",
    "        # PopulationReboot -------------------------------------------------------------------------------\n",
    "        self.doPopulationReboot = doPopulationReboot # bool(int(par['doPopulationReboot']))          #Saved as Boolean\n",
    "        self.popRebootPath = popRebootPath #par['popRebootPath']                               #Saved as text\n",
    "        \n",
    "        \n",
    "    def referenceEnv(self, e):\n",
    "        \"\"\" Store reference to environment object. \"\"\"\n",
    "        self.env = e\n",
    " \n",
    "        \n",
    "    def parseIterations(self):\n",
    "        #\"\"\" Parse the 'learningIterations' string to identify the maximum number of learning iterations as well as evaluation checkpoints. \"\"\"\n",
    "        #checkpoints = self.learningIterations.split('.') \n",
    "        \n",
    "        #for i in range(len(checkpoints)): \n",
    "           # checkpoints[i] = int(checkpoints[i])\n",
    "            \n",
    "        # self.learningCheckpoints = checkpoints #next two lines needed for reboot\n",
    "        # self.maxLearningIterations = self.learningCheckpoints[(len(self.learningCheckpoints)-1)] #???\n",
    "\n",
    "        self.learningCheckpoints = 64\n",
    "        self.maxLearningIterations = learningIterations\n",
    "        \n",
    "        if self.trackingFrequency == 0:\n",
    "            self.trackingFrequency = self.env.formatData.numTrainInstances  #Adjust tracking frequency to match the training data size - learning tracking occurs once every epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "hideCode": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#To access one of the above constant values from another module, import GHCS_Constants * and use \"cons.something\"\n",
    "cons = Constants() \n",
    "cons.setConstants() #Store run parameters in the 'Constants' module.\n",
    "cons.parseIterations() #Store run parameters in the 'Constants' module.\n",
    "#print(cons.maxLearningIterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false
   },
   "source": [
    "Data management, e.g. load data from a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "hideCode": true
   },
   "outputs": [],
   "source": [
    "class DataManagement:\n",
    "    def __init__(self, trainFile, testFile, infoList = None):\n",
    "        #Set random seed if specified.-----------------------------------------------\n",
    "        if cons.useSeed:\n",
    "            random.seed(cons.randomSeed)\n",
    "        else:\n",
    "            random.seed(None)\n",
    "\n",
    "        #Initialize global variables-------------------------------------------------\n",
    "        self.numAttributes = None       # The number of attributes in the input file. \n",
    "        self.areInstanceIDs = False     # Does the dataset contain a column of Instance IDs? (If so, it will not be included as an attribute)\n",
    "        self.instanceIDRef = None       # The column reference for Instance IDs\n",
    "        self.phenotypeRef = None        # The column reference for the Class/Phenotype column\n",
    "        self.discretePhenotype = True   # Is the Class/Phenotype Discrete? (False = Continuous)\n",
    "        self.attributeInfo = []         # Stores Discrete (0) or Continuous (1) for each attribute\n",
    "        self.phenotypeList = []         # Stores all possible discrete phenotype states/classes or maximum and minimum values for a continuous phenotype\n",
    "        self.phenotypeRange = None      # Stores the difference between the maximum and minimum values for a continuous phenotype\n",
    "        \n",
    "        #Train/Test Specific-----------------------------------------------------------------------------\n",
    "        self.trainHeaderList = []       # The dataset column headers for the training data\n",
    "        self.testHeaderList = []        # The dataset column headers for the testing data\n",
    "        self.numTrainInstances = None   # The number of instances in the training data\n",
    "        self.numTestInstances = None    # The number of instances in the testing data\n",
    "        \n",
    "        print(\"----------------------------------------------------------------------------\")\n",
    "        print(\"Environment: Formatting Data... \")\n",
    "        \n",
    "        #Detect Features of training data--------------------------------------------------------------------------\n",
    "        rawTrainData = self.loadData(trainFile, True) #Load the raw data.\n",
    "\n",
    "        self.characterizeDataset(rawTrainData)  #Detect number of attributes, instances, and reference locations.\n",
    "        \n",
    "        if cons.testFile == 'None': #If no testing data is available, formatting relies solely on training data.\n",
    "            data4Formating = rawTrainData\n",
    "        else:\n",
    "            rawTestData = self.loadData(testFile, False) #Load the raw data.\n",
    "            self.compareDataset(rawTestData) #Ensure that key features are the same between training and testing datasets.\n",
    "            data4Formating = rawTrainData + rawTestData #Merge Training and Testing datasets\n",
    "\n",
    "        self.discriminatePhenotype(data4Formating) #Determine if endpoint/phenotype is discrete or continuous.\n",
    "        if self.discretePhenotype:\n",
    "            self.discriminateClasses(data4Formating) #Detect number of unique phenotype identifiers.\n",
    "        else:\n",
    "            self.characterizePhenotype(data4Formating)\n",
    "            \n",
    "        self.discriminateAttributes(data4Formating) #Detect whether attributes are discrete or continuous.\n",
    "        self.characterizeAttributes(data4Formating) #Determine potential attribute states or ranges.\n",
    "        \n",
    "        #Format and Shuffle Datasets----------------------------------------------------------------------------------------\n",
    "        if cons.testFile != 'None':\n",
    "            self.testFormatted = self.formatData(rawTestData) #Stores the formatted testing data set used throughout the algorithm.\n",
    "\n",
    "        self.trainFormatted = self.formatData(rawTrainData) #Stores the formatted training data set used throughout the algorithm.       \n",
    "        print(\"----------------------------------------------------------------------------\")\n",
    "\n",
    "        \n",
    "    def loadData(self, dataFile, doTrain):\n",
    "        \"\"\" Load the data file. \"\"\"     \n",
    "        print(\"DataManagement: Loading Data... \" + str(dataFile))\n",
    "        datasetList = []\n",
    "        try:       \n",
    "            f = open(dataFile,'r')\n",
    "        except Exception as inst:\n",
    "            print(type(inst))\n",
    "            print(inst.args)\n",
    "            print(inst)\n",
    "            print('cannot open', dataFile)\n",
    "            raise\n",
    "            \n",
    "        else:\n",
    "            if doTrain:\n",
    "                self.trainHeaderList = f.readline().rstrip('\\n').split('\\t')   #strip off first row\n",
    "            else:\n",
    "                self.testHeaderList = f.readline().rstrip('\\n').split('\\t')   #strip off first row\n",
    "            for line in f:\n",
    "                lineList = line.strip('\\n').split('\\t')\n",
    "                datasetList.append(lineList)\n",
    "            f.close()\n",
    "\n",
    "        return datasetList\n",
    "    \n",
    "    \n",
    "    def characterizeDataset(self, rawTrainData):\n",
    "        \" Detect basic dataset parameters \" \n",
    "        #Detect Instance ID's and save location if they occur.  Then save number of attributes in data.\n",
    "        if cons.labelInstanceID in self.trainHeaderList:\n",
    "            self.areInstanceIDs = True\n",
    "            self.instanceIDRef = self.trainHeaderList.index(cons.labelInstanceID)\n",
    "            print(\"DataManagement: Instance ID Column location = \"+str(self.instanceIDRef))\n",
    "            self.numAttributes = len(self.trainHeaderList)-2 #one column for InstanceID and another for the phenotype.\n",
    "        else:\n",
    "            self.numAttributes = len(self.trainHeaderList)-1\n",
    "        \n",
    "        #Identify location of phenotype column\n",
    "        if cons.labelPhenotype in self.trainHeaderList:\n",
    "            self.phenotypeRef = self.trainHeaderList.index(cons.labelPhenotype)\n",
    "            print(\"DataManagement: Phenotype Column Location = \"+str(self.phenotypeRef))\n",
    "        else:\n",
    "            print(\"DataManagement: Error - Phenotype column not found!  Check data set to ensure correct phenotype column label, or inclusion in the data.\")\n",
    "\n",
    "        #Adjust training header list to just include attributes labels\n",
    "        if self.areInstanceIDs:\n",
    "            if self.phenotypeRef > self.instanceIDRef:\n",
    "                self.trainHeaderList.pop(self.phenotypeRef)\n",
    "                self.trainHeaderList.pop(self.instanceIDRef)\n",
    "            else:\n",
    "                self.trainHeaderList.pop(self.instanceIDRef)\n",
    "                self.trainHeaderList.pop(self.phenotypeRef)\n",
    "        else:\n",
    "            self.trainHeaderList.pop(self.phenotypeRef)\n",
    "        \n",
    "        #Store number of instances in training data\n",
    "        self.numTrainInstances = len(rawTrainData)\n",
    "        print(\"DataManagement: Number of Attributes = \" + str(self.numAttributes)) \n",
    "        print(\"DataManagement: Number of Instances = \" + str(self.numTrainInstances)) \n",
    "\n",
    "\n",
    "    def discriminatePhenotype(self, rawData):\n",
    "        \"\"\" Determine whether the phenotype is Discrete(class-based) or Continuous \"\"\"\n",
    "        print(\"DataManagement: Analyzing Phenotype...\")\n",
    "        inst = 0\n",
    "        classDict = {}\n",
    "        while self.discretePhenotype and len(list(classDict.keys())) <= cons.discreteAttributeLimit and inst < self.numTrainInstances:  #Checks which discriminate between discrete and continuous attribute\n",
    "            target = rawData[inst][self.phenotypeRef]\n",
    "            if target in list(classDict.keys()):  #Check if we've seen this attribute state yet.\n",
    "                classDict[target] += 1\n",
    "            elif target == cons.labelMissingData: #Ignore missing data\n",
    "                print(\"DataManagement: Warning - Individual detected with missing phenotype information!\")\n",
    "                pass\n",
    "            else: #New state observed\n",
    "                classDict[target] = 1\n",
    "            inst += 1\n",
    "\n",
    "        if len(list(classDict.keys())) > cons.discreteAttributeLimit:\n",
    "            self.discretePhenotype = False\n",
    "            self.phenotypeList = [float(target),float(target)]\n",
    "            print(\"DataManagement: Phenotype Detected as Continuous.\")\n",
    "        else:\n",
    "            print(\"DataManagement: Phenotype Detected as Discrete.\")\n",
    "            \n",
    "    \n",
    "    def discriminateClasses(self, rawData):\n",
    "        \"\"\" Determines number of classes and their identifiers. Only used if phenotype is discrete. \"\"\"\n",
    "        print(\"DataManagement: Detecting Classes...\")\n",
    "        inst = 0\n",
    "        classCount = {}\n",
    "        while inst < self.numTrainInstances:\n",
    "            target = rawData[inst][self.phenotypeRef]\n",
    "            if target in self.phenotypeList:\n",
    "                classCount[target] += 1 \n",
    "            else:\n",
    "                self.phenotypeList.append(target)\n",
    "                classCount[target] = 1\n",
    "            inst += 1\n",
    "        print(\"DataManagement: Following Classes Detected:\" + str(self.phenotypeList))\n",
    "        for each in list(classCount.keys()):\n",
    "            print(\"Class: \"+str(each)+ \" count = \"+ str(classCount[each]))\n",
    "            \n",
    "                     \n",
    "    def compareDataset(self, rawTestData):\n",
    "        \" Ensures that the attributes in the testing data match those in the training data.  Also stores some information about the testing data. \"\n",
    "        if self.areInstanceIDs:\n",
    "            if self.phenotypeRef > self.instanceIDRef:\n",
    "                self.testHeaderList.pop(self.phenotypeRef)\n",
    "                self.testHeaderList.pop(self.instanceIDRef)\n",
    "            else:\n",
    "                self.testHeaderList.pop(self.instanceIDRef)\n",
    "                self.testHeaderList.pop(self.phenotypeRef)\n",
    "        else:\n",
    "            self.testHeaderList.pop(self.phenotypeRef)\n",
    "            \n",
    "        if self.trainHeaderList != self.testHeaderList:\n",
    "            print(\"DataManagement: Error - Training and Testing Dataset Headers are not equivalent\")\n",
    "\n",
    "        # Stores the number of instances in the testing data.\n",
    "        self.numTestInstances = len(rawTestData)\n",
    "        print(\"DataManagement: Number of Attributes = \" + str(self.numAttributes)) \n",
    "        print(\"DataManagement: Number of Instances = \" + str(self.numTestInstances)) \n",
    "\n",
    "\n",
    "    def discriminateAttributes(self, rawData):\n",
    "        \"\"\" Determine whether attributes in dataset are discrete or continuous and saves this information. \"\"\"\n",
    "        print(\"DataManagement: Detecting Attributes...\")\n",
    "        self.discreteCount = 0\n",
    "        self.continuousCount = 0\n",
    "        for att in range(len(rawData[0])):\n",
    "            if att != self.instanceIDRef and att != self.phenotypeRef:  #Get just the attribute columns (ignores phenotype and instanceID columns)\n",
    "                attIsDiscrete = True\n",
    "                inst = 0\n",
    "                stateDict = {}\n",
    "                while attIsDiscrete and len(list(stateDict.keys())) <= cons.discreteAttributeLimit and inst < self.numTrainInstances:  #Checks which discriminate between discrete and continuous attribute\n",
    "                    target = rawData[inst][att]\n",
    "                    if target in list(stateDict.keys()):  #Check if we've seen this attribute state yet.\n",
    "                        stateDict[target] += 1\n",
    "                    elif target == cons.labelMissingData: #Ignore missing data\n",
    "                        pass\n",
    "                    else: #New state observed\n",
    "                        stateDict[target] = 1\n",
    "                    inst += 1\n",
    "\n",
    "                if len(list(stateDict.keys())) > cons.discreteAttributeLimit:\n",
    "                    attIsDiscrete = False\n",
    "                if attIsDiscrete:\n",
    "                    self.attributeInfo.append([0,[]])    \n",
    "                    self.discreteCount += 1\n",
    "                else:\n",
    "                    self.attributeInfo.append([1,[float(target),float(target)]])   #[min,max]\n",
    "                    self.continuousCount += 1\n",
    "        print(\"DataManagement: Identified \"+str(self.discreteCount)+\" discrete and \"+str(self.continuousCount)+\" continuous attributes.\") #Debug\n",
    "\n",
    "            \n",
    "    def characterizeAttributes(self, rawData):\n",
    "        \"\"\" Determine range (if continuous) or states (if discrete) for each attribute and saves this information\"\"\"\n",
    "        print(\"DataManagement: Characterizing Attributes...\")\n",
    "        attributeID = 0\n",
    "        for att in range(len(rawData[0])):\n",
    "            if att != self.instanceIDRef and att != self.phenotypeRef:  #Get just the attribute columns (ignores phenotype and instanceID columns)\n",
    "                for inst in range(len(rawData)):\n",
    "                    target = rawData[inst][att]\n",
    "                    if not self.attributeInfo[attributeID][0]: #If attribute is discrete\n",
    "                        if target in self.attributeInfo[attributeID][1] or target == cons.labelMissingData:\n",
    "                            pass  #NOTE: Could potentially store state frequency information to guide learning.\n",
    "                        else:\n",
    "                            self.attributeInfo[attributeID][1].append(target)\n",
    "                    else: #If attribute is continuous\n",
    "                        \n",
    "                        #Find Minimum and Maximum values for the continuous attribute so we know the range.\n",
    "                        if target == cons.labelMissingData:\n",
    "                            pass\n",
    "                        elif float(target) > self.attributeInfo[attributeID][1][1]:  #error\n",
    "                            self.attributeInfo[attributeID][1][1] = float(target)\n",
    "                        elif float(target) < self.attributeInfo[attributeID][1][0]:\n",
    "                            self.attributeInfo[attributeID][1][0] = float(target)\n",
    "                        else:\n",
    "                            pass\n",
    "                attributeID += 1\n",
    "                \n",
    "\n",
    "    def characterizePhenotype(self, rawData):\n",
    "        \"\"\" Determine range of phenotype values. \"\"\"\n",
    "        print(\"DataManagement: Characterizing Phenotype...\")\n",
    "        for inst in range(len(rawData)):\n",
    "            target = rawData[inst][self.phenotypeRef]\n",
    "            \n",
    "            #Find Minimum and Maximum values for the continuous phenotype so we know the range.\n",
    "            if target == cons.labelMissingData:\n",
    "                pass\n",
    "            elif float(target) > self.phenotypeList[1]:  \n",
    "                self.phenotypeList[1] = float(target)\n",
    "            elif float(target) < self.phenotypeList[0]:\n",
    "                self.phenotypeList[0] = float(target)\n",
    "            else:\n",
    "                pass\n",
    "        self.phenotypeRange = self.phenotypeList[1] - self.phenotypeList[0]\n",
    "                \n",
    "            \n",
    "    def formatData(self,rawData):\n",
    "        \"\"\" Get the data into a format convenient for the algorithm to interact with. Specifically each instance is stored in a list as follows; [Attribute States, Phenotype, InstanceID] \"\"\"\n",
    "        formatted = []\n",
    "        #Initialize data format---------------------------------------------------------\n",
    "        for i in range(len(rawData)):  \n",
    "            formatted.append([None,None,None]) #[Attribute States, Phenotype, InstanceID]\n",
    "\n",
    "        for inst in range(len(rawData)):\n",
    "            stateList = []\n",
    "            attributeID = 0\n",
    "            for att in range(len(rawData[0])):\n",
    "                if att != self.instanceIDRef and att != self.phenotypeRef:  #Get just the attribute columns (ignores phenotype and instanceID columns)\n",
    "                    target = rawData[inst][att]\n",
    "                    \n",
    "                    if self.attributeInfo[attributeID][0]: #If the attribute is continuous\n",
    "                        if target == cons.labelMissingData:\n",
    "                            stateList.append(target) #Missing data saved as text label\n",
    "                        else:\n",
    "                            stateList.append(float(target)) #Save continuous data as floats. \n",
    "                    else: #If the attribute is discrete - Format the data to correspond to the GABIL (DeJong 1991)\n",
    "                        stateList.append(target) #missing data, and discrete variables, all stored as string objects   \n",
    "                    attributeID += 1\n",
    "            \n",
    "            #Final Format-----------------------------------------------\n",
    "            formatted[inst][0] = stateList                           #Attribute states stored here\n",
    "            if self.discretePhenotype:\n",
    "                formatted[inst][1] = rawData[inst][self.phenotypeRef]        #phenotype stored here\n",
    "            else:\n",
    "                formatted[inst][1] = float(rawData[inst][self.phenotypeRef])\n",
    "            if self.areInstanceIDs:\n",
    "                formatted[inst][2] = rawData[inst][self.instanceIDRef]   #Instance ID stored here\n",
    "            else:\n",
    "                pass    #instance ID neither given nor required.\n",
    "            #-----------------------------------------------------------\n",
    "        random.shuffle(formatted) #One time randomization of the order the of the instances in the data, so that if the data was ordered by phenotype, this potential learning bias (based on instance ordering) is eliminated.  \n",
    "        return formatted\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Offline environment: class to cycle through an offline dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "hideCode": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class Offline_Environment:\n",
    "    def __init__(self):\n",
    "        #Initialize global variables-------------------------------------------------\n",
    "        self.dataRef = 0\n",
    "        self.storeDataRef = 0\n",
    "        self.formatData = DataManagement(cons.trainFile, cons.testFile)\n",
    "        \n",
    "        #Initialize the first dataset instance to be passed to eLCS\n",
    "        self.currentTrainState = self.formatData.trainFormatted[self.dataRef][0]\n",
    "        self.currentTrainPhenotype = self.formatData.trainFormatted[self.dataRef][1]\n",
    "        if cons.testFile == 'None':\n",
    "            pass\n",
    "        else:\n",
    "            self.currentTestState = self.formatData.testFormatted[self.dataRef][0]\n",
    "            self.currentTestPhenotype = self.formatData.testFormatted[self.dataRef][1]\n",
    "        \n",
    "\n",
    "    def getTrainInstance(self):\n",
    "        \"\"\" Returns the current training instance. \"\"\" \n",
    "        return [self.currentTrainState, self.currentTrainPhenotype]\n",
    "        \n",
    "        \n",
    "    def getTestInstance(self):\n",
    "        \"\"\" Returns the current training instance. \"\"\"\n",
    "        return [self.currentTestState, self.currentTestPhenotype]\n",
    "    \n",
    "    \n",
    "    def newInstance(self, isTraining): \n",
    "        \"\"\"  Shifts the environment to the next instance in the data. \"\"\"\n",
    "        #-------------------------------------------------------\n",
    "        # Training Data\n",
    "        #-------------------------------------------------------\n",
    "        if isTraining: \n",
    "            if self.dataRef < (self.formatData.numTrainInstances-1):\n",
    "                self.dataRef += 1\n",
    "                self.currentTrainState = self.formatData.trainFormatted[self.dataRef][0]\n",
    "                self.currentTrainPhenotype = self.formatData.trainFormatted[self.dataRef][1]\n",
    "            else:  #Once learning has completed an epoch (i.e. a cycle of iterations though the entire training dataset) it starts back at the first instance in the data)\n",
    "                self.resetDataRef(isTraining)\n",
    "                \n",
    "        #-------------------------------------------------------\n",
    "        # Testing Data\n",
    "        #-------------------------------------------------------\n",
    "        else:\n",
    "            if self.dataRef < (self.formatData.numTestInstances-1):\n",
    "                self.dataRef += 1\n",
    "                self.currentTestState = self.formatData.testFormatted[self.dataRef][0]\n",
    "                self.currentTestPhenotype = self.formatData.testFormatted[self.dataRef][1]\n",
    "      \n",
    "      \n",
    "    def resetDataRef(self, isTraining):\n",
    "        \"\"\" Resets the environment back to the first instance in the current data set. \"\"\"\n",
    "        self.dataRef = 0 \n",
    "        if isTraining:\n",
    "            self.currentTrainState = self.formatData.trainFormatted[self.dataRef][0]\n",
    "            self.currentTrainPhenotype = self.formatData.trainFormatted[self.dataRef][1]\n",
    "        else:\n",
    "            self.currentTestState = self.formatData.testFormatted[self.dataRef][0]\n",
    "            self.currentTestPhenotype = self.formatData.testFormatted[self.dataRef][1]\n",
    "\n",
    "\n",
    "    def startEvaluationMode(self):\n",
    "        \"\"\" Turns on evaluation mode.  Saves the instance we left off in the training data. \"\"\"\n",
    "        self.storeDataRef = self.dataRef\n",
    "        \n",
    "        \n",
    "    def stopEvaluationMode(self):\n",
    "        \"\"\" Turns off evaluation mode.  Re-establishes place in dataset.\"\"\"\n",
    "        self.dataRef = self.storeDataRef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifier class! Worth reading :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "hideCode": true
   },
   "outputs": [],
   "source": [
    "class Classifier:\n",
    "    def __init__(self,a=None,b=None,c=None,d=None):\n",
    "        #Major Parameters --------------------------------------------------\n",
    "        self.specifiedAttList = []      # Attribute Specified in classifier: Similar to Bacardit 2009 - ALKR + GABIL, continuous and discrete rule representation\n",
    "        self.condition = []             # States of Attributes Specified in classifier: Similar to Bacardit 2009 - ALKR + GABIL, continuous and discrete rule representation\n",
    "        self.phenotype = None           # Class if the endpoint is discrete, and a continuous phenotype if the endpoint is continuous\n",
    "        \n",
    "        self.fitness = cons.init_fit    # Classifier fitness - initialized to a constant initial fitness value\n",
    "        self.accuracy = 0.0             # Classifier accuracy - Accuracy calculated using only instances in the dataset which this rule matched.\n",
    "        \n",
    "        #Experience Management ---------------------------------------------\n",
    "        self.initTimeStamp = None       # Iteration in which the rule first appeared.\n",
    "        \n",
    "        #Classifier Accuracy Tracking --------------------------------------\n",
    "        self.matchCount = 0             # Known in many LCS implementations as experience i.e. the total number of times this classifier was in a match set\n",
    "        self.correctCount = 0           # The total number of times this classifier was in a correct set\n",
    "        \n",
    "        if isinstance(b,list):\n",
    "            self.classifierCovering(a,b,c)\n",
    "        elif isinstance(a,Classifier):\n",
    "            self.classifierCopy(a, b)\n",
    "        elif isinstance(a,list) and b == None:\n",
    "            self.rebootClassifier(a)\n",
    "        else:\n",
    "            print(\"Classifier: Error building classifier.\")\n",
    "            \n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    # CLASSIFIER CONSTRUCTION METHODS\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------       \n",
    "    def classifierCovering(self, exploreIter, state, phenotype):\n",
    "        \"\"\" Makes a new classifier when the covering mechanism is triggered.  The new classifier will match the current training instance. \n",
    "        Covering will NOT produce a default rule (i.e. a rule with a completely general condition). \"\"\"\n",
    "        #Initialize new classifier parameters----------\n",
    "        self.initTimeStamp = exploreIter\n",
    "        dataInfo = cons.env.formatData\n",
    "        #-------------------------------------------------------\n",
    "        # DISCRETE PHENOTYPE\n",
    "        #-------------------------------------------------------\n",
    "        if dataInfo.discretePhenotype: \n",
    "            self.phenotype = phenotype\n",
    "        #-------------------------------------------------------\n",
    "        # CONTINUOUS PHENOTYPE\n",
    "        #-------------------------------------------------------\n",
    "        else:\n",
    "            phenotypeRange = dataInfo.phenotypeList[1] - dataInfo.phenotypeList[0]\n",
    "            rangeRadius = random.randint(25,75)*0.01*phenotypeRange / 2.0 #Continuous initialization domain radius.\n",
    "            Low = float(phenotype) - rangeRadius\n",
    "            High = float(phenotype) + rangeRadius\n",
    "            self.phenotype = [Low,High] #ALKR Representation, Initialization centered around training instance  with a range between 25 and 75% of the domain size.      \n",
    "        #-------------------------------------------------------\n",
    "        # GENERATE MATCHING CONDITION\n",
    "        #-------------------------------------------------------\n",
    "        while len(self.specifiedAttList) < 1:\n",
    "            for attRef in range(len(state)):\n",
    "                if random.random() < cons.p_spec and state[attRef] != cons.labelMissingData:\n",
    "                    self.specifiedAttList.append(attRef)\n",
    "                    self.condition.append(self.buildMatch(attRef, state))\n",
    "        \n",
    "        \n",
    "    def rebootClassifier(self, classifierList): \n",
    "        \"\"\" Rebuilds a saved classifier as part of the population Reboot \"\"\"\n",
    "        numAttributes = cons.env.formatData.numAttributes\n",
    "        attInfo = cons.env.formatData.attributeInfo\n",
    "        for attRef in range(0,numAttributes):\n",
    "            if classifierList[attRef] != '#':  #Attribute in rule is not wild\n",
    "                if attInfo[attRef][0]: #Continuous Attribute\n",
    "                    valueRange = classifierList[attRef].split(';')\n",
    "                    self.condition.append(valueRange)\n",
    "                    self.specifiedAttList.append(attRef)\n",
    "                else:\n",
    "                    self.condition.append(classifierList[attRef])\n",
    "                    self.specifiedAttList.append(attRef)\n",
    "        #-------------------------------------------------------\n",
    "        # DISCRETE PHENOTYPE\n",
    "        #-------------------------------------------------------\n",
    "        if cons.env.formatData.discretePhenotype: \n",
    "            self.phenotype = str(classifierList[numAttributes])\n",
    "        #-------------------------------------------------------\n",
    "        # CONTINUOUS PHENOTYPE\n",
    "        #-------------------------------------------------------\n",
    "        else:\n",
    "            self.phenotype = classifierList[numAttributes].split(';')\n",
    "            for i in range(2): \n",
    "                self.phenotype[i] = float(self.phenotype[i])\n",
    "\n",
    "        self.fitness = float(classifierList[numAttributes+1])\n",
    "        self.accuracy = float(classifierList[numAttributes+2])\n",
    "        self.initTimeStamp = int(classifierList[numAttributes+6])\n",
    "        \n",
    "        self.correctCount = int(classifierList[numAttributes+9])\n",
    "        self.matchCount = int(classifierList[numAttributes+10])\n",
    "\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    # MATCHING\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------  \n",
    "    def match(self, state):\n",
    "        \"\"\" Returns if the classifier matches in the current situation. \"\"\" \n",
    "        for i in range(len(self.condition)):\n",
    "            attributeInfo = cons.env.formatData.attributeInfo[self.specifiedAttList[i]]\n",
    "            #-------------------------------------------------------\n",
    "            # CONTINUOUS ATTRIBUTE\n",
    "            #-------------------------------------------------------\n",
    "            if attributeInfo[0]:\n",
    "                instanceValue = state[self.specifiedAttList[i]]\n",
    "                if self.condition[i][0] < instanceValue < self.condition[i][1] or instanceValue == cons.labelMissingData:\n",
    "                    pass\n",
    "                else:\n",
    "                    return False  \n",
    "            #-------------------------------------------------------\n",
    "            # DISCRETE ATTRIBUTE\n",
    "            #-------------------------------------------------------\n",
    "            else:\n",
    "                stateRep = state[self.specifiedAttList[i]]  \n",
    "                if stateRep == self.condition[i] or stateRep == cons.labelMissingData:\n",
    "                    pass\n",
    "                else:\n",
    "                    return False \n",
    "        return True\n",
    "        \n",
    "   \n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    # OTHER METHODS\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------  \n",
    "    def buildMatch(self, attRef, state):\n",
    "        \"\"\" Builds a matching condition for the classifierCovering method. \"\"\"\n",
    "        attributeInfo = cons.env.formatData.attributeInfo[attRef]\n",
    "        #-------------------------------------------------------\n",
    "        # CONTINUOUS ATTRIBUTE\n",
    "        #-------------------------------------------------------\n",
    "        if attributeInfo[0]:\n",
    "            attRange = attributeInfo[1][1] - attributeInfo[1][0]\n",
    "            rangeRadius = random.randint(25,75)*0.01*attRange / 2.0 #Continuous initialization domain radius.\n",
    "            Low = state[attRef] - rangeRadius\n",
    "            High = state[attRef] + rangeRadius\n",
    "            condList = [Low,High] #ALKR Representation, Initialization centered around training instance  with a range between 25 and 75% of the domain size.\n",
    "        #-------------------------------------------------------\n",
    "        # DISCRETE ATTRIBUTE\n",
    "        #-------------------------------------------------------\n",
    "        else: \n",
    "            condList = state[attRef] #State already formatted like GABIL in DataManagement\n",
    "            \n",
    "        return condList\n",
    "     \n",
    "\n",
    "    def equals(self, cl):  \n",
    "        \"\"\" Returns if the two classifiers are identical in condition and phenotype. This works for discrete or continuous attributes or phenotypes. \"\"\" \n",
    "        if cl.phenotype == self.phenotype and len(cl.specifiedAttList) == len(self.specifiedAttList): #Is phenotype the same and are the same number of attributes specified - quick equality check first.\n",
    "            clRefs = sorted(cl.specifiedAttList)\n",
    "            selfRefs = sorted(self.specifiedAttList)\n",
    "            if clRefs == selfRefs:\n",
    "                for i in range(len(cl.specifiedAttList)):\n",
    "                    tempIndex = self.specifiedAttList.index(cl.specifiedAttList[i])\n",
    "                    if cl.condition[i] == self.condition[tempIndex]:\n",
    "                        pass\n",
    "                    else:\n",
    "                        return False\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    # PARAMETER UPDATES\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------        \n",
    "    def updateAccuracy(self):\n",
    "        \"\"\" Update the accuracy tracker \"\"\"\n",
    "        self.accuracy = self.correctCount / float(self.matchCount)\n",
    "        \n",
    "        \n",
    "    def updateFitness(self):\n",
    "        \"\"\" Update the fitness parameter. \"\"\" \n",
    "        if cons.env.formatData.discretePhenotype or (self.phenotype[1]-self.phenotype[0])/cons.env.formatData.phenotypeRange < 0.5:\n",
    "            self.fitness = pow(self.accuracy, cons.nu)\n",
    "        else:\n",
    "            if (self.phenotype[1]-self.phenotype[0]) >= cons.env.formatData.phenotypeRange:\n",
    "                self.fitness = 0.0\n",
    "            else:\n",
    "                self.fitness = math.fabs(pow(self.accuracy, cons.nu) - (self.phenotype[1]-self.phenotype[0])/cons.env.formatData.phenotypeRange)\n",
    "\n",
    "        \n",
    "    def updateExperience(self):\n",
    "        \"\"\" Increases the experience of the classifier by one. Once an epoch has completed, rule accuracy can't change.\"\"\"\n",
    "        self.matchCount += 1 \n",
    "\n",
    "\n",
    "    def updateCorrect(self):\n",
    "        \"\"\" Increases the correct phenotype tracking by one. Once an epoch has completed, rule accuracy can't change.\"\"\"\n",
    "        self.correctCount += 1 \n",
    "\n",
    "        \n",
    "    def setAccuracy(self,acc):\n",
    "        \"\"\" Sets the accuracy of the classifier \"\"\"\n",
    "        self.accuracy = acc\n",
    "        \n",
    "        \n",
    "    def setFitness(self, fit):\n",
    "        \"\"\"  Sets the fitness of the classifier. \"\"\"\n",
    "        self.fitness = fit\n",
    "        \n",
    "    def reportClassifier(self):\n",
    "        \"\"\"  Transforms the rule representation used to a more standard readable format. \"\"\"\n",
    "        numAttributes = cons.env.formatData.numAttributes\n",
    "        thisClassifier = []\n",
    "        counter = 0\n",
    "        for i in range(numAttributes):\n",
    "            if i in self.specifiedAttList:\n",
    "                thisClassifier.append(self.condition[counter])\n",
    "                counter += 1\n",
    "            else:\n",
    "                thisClassifier.append('#')\n",
    "        return thisClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifier Set class, again a must read :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "hideCode": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class ClassifierSet:\n",
    "    def __init__(self, a=None):\n",
    "        \"\"\" Overloaded initialization: Handles creation of a new population or a rebooted population (i.e. a previously saved population). \"\"\"\n",
    "        # Major Parameters\n",
    "        self.popSet = []        # List of classifiers/rules\n",
    "        self.matchSet = []      # List of references to rules in population that match\n",
    "        self.correctSet = []    # List of references to rules in population that both match and specify correct phenotype\n",
    "        self.microPopSize = 0   # Tracks the current micro population size \n",
    "        \n",
    "        # Evaluation Parameters-------------------------------\n",
    "        self.aveGenerality = 0.0\n",
    "        self.expRules = 0.0\n",
    "        self.attributeSpecList = []\n",
    "        self.attributeAccList = []\n",
    "        self.avePhenotypeRange = 0.0\n",
    "\n",
    "        # Set Constructors-------------------------------------\n",
    "        if a==None:\n",
    "            self.makePop() #Initialize a new population\n",
    "        elif isinstance(a,str):\n",
    "            self.rebootPop(a) #Initialize a population based on an existing saved rule population\n",
    "        else:\n",
    "            print(\"ClassifierSet: Error building population.\")\n",
    "            \n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    # POPULATION CONSTRUCTOR METHODS\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    def makePop(self):\n",
    "        \"\"\" Initializes the rule population \"\"\"\n",
    "        self.popSet = []\n",
    "            \n",
    "            \n",
    "    def rebootPop(self, remakeFile):\n",
    "        \"\"\" Remakes a previously evolved population from a saved text file. \"\"\"\n",
    "        print(\"Rebooting the following population: \" + str(remakeFile)+\"_RulePop.txt\")\n",
    "        #*******************Initial file handling**********************************************************\n",
    "        try:       \n",
    "            datasetList = []\n",
    "            f = open(remakeFile+\"_RulePop.txt\", 'r')\n",
    "        except Exception as inst:\n",
    "            print(type(inst))\n",
    "            print(inst.args)\n",
    "            print(inst)\n",
    "            print('cannot open', remakeFile+\"_RulePop.txt\")\n",
    "            raise\n",
    "        else:\n",
    "            self.headerList = f.readline().rstrip('\\n').split('\\t')   #strip off first row\n",
    "            for line in f:\n",
    "                lineList = line.strip('\\n').split('\\t')\n",
    "                datasetList.append(lineList)\n",
    "            f.close()    \n",
    "            \n",
    "        #**************************************************************************************************\n",
    "        for each in datasetList:\n",
    "            cl = Classifier(each)\n",
    "            self.popSet.append(cl) \n",
    "            self.microPopSize += 1\n",
    "        print(\"Rebooted Rule Population has \"+str(len(self.popSet))+\" Macro Pop Size.\")\n",
    "        \n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    # CLASSIFIER SET CONSTRUCTOR METHODS\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    def makeMatchSet(self, state_phenotype, exploreIter):\n",
    "        \"\"\" Constructs a match set from the population. Covering is initiated if the match set is empty or a rule with the current correct phenotype is absent. \"\"\" \n",
    "        #BREAK 2 DEMO CODE-------------------------\n",
    "        print(\"Current instance from dataset:  \" + \"State = \"+ str(state_phenotype[0]) + \"  Phenotype = \"+ str(state_phenotype[1]))\n",
    "        print(\"--------------------------------------------------------------------------------------\")\n",
    "        print(\"Matching Classifiers:\")\n",
    "        #------------------------------------------\n",
    "        #Initial values\n",
    "        state = state_phenotype[0]\n",
    "        phenotype = state_phenotype[1]\n",
    "        doCovering = True # Covering check: Twofold (1)checks that a match is present, and (2) that at least one match dictates the correct phenotype.\n",
    "        \n",
    "        #-------------------------------------------------------\n",
    "        # MATCHING\n",
    "        #-------------------------------------------------------\n",
    "        for i in range(len(self.popSet)):           # Go through the population\n",
    "            cl = self.popSet[i]                     # One classifier at a time\n",
    "            if cl.match(state):                     # Check for match\n",
    "                #BREAK 2 DEMO CODE-------------------------\n",
    "                print(\"Condition: \"+ str(cl.reportClassifier()) + \"  Phenotype: \"+ str(cl.phenotype))\n",
    "                #------------------------------------------\n",
    "                self.matchSet.append(i)             # If match - add classifier to match set\n",
    "                \n",
    "                #Covering Check--------------------------------------------------------    \n",
    "                if cons.env.formatData.discretePhenotype:   # Discrete phenotype     \n",
    "                    if cl.phenotype == phenotype:           # Check for phenotype coverage\n",
    "                        doCovering = False\n",
    "                else:                                                                           # Continuous phenotype\n",
    "                    if float(cl.phenotype[0]) <= float(phenotype) <= float(cl.phenotype[1]):    # Check for phenotype coverage\n",
    "                        doCovering = False\n",
    "        if len(self.matchSet) == 0:\n",
    "            print('None found.')\n",
    "        #-------------------------------------------------------\n",
    "        # COVERING\n",
    "        #-------------------------------------------------------\n",
    "        while doCovering:\n",
    "            newCl = Classifier(exploreIter, state, phenotype)\n",
    "            #BREAK 2 DEMO CODE-------------------------\n",
    "            print(\"Covering Activated:\")\n",
    "            print(\"Condition: \"+ str(newCl.reportClassifier()) + \"  Phenotype: \"+ str(newCl.phenotype))\n",
    "            #------------------------------------------\n",
    "            self.addClassifierToPopulation(newCl)\n",
    "            self.matchSet.append(len(self.popSet)-1)  # Add covered classifier to matchset\n",
    "            doCovering = False\n",
    "        \n",
    "        \n",
    "    def makeCorrectSet(self, phenotype):\n",
    "        \"\"\" Constructs a correct set out of the given match set. \"\"\"      \n",
    "        for i in range(len(self.matchSet)):\n",
    "            ref = self.matchSet[i]\n",
    "            #-------------------------------------------------------\n",
    "            # DISCRETE PHENOTYPE\n",
    "            #-------------------------------------------------------\n",
    "            if cons.env.formatData.discretePhenotype: \n",
    "                if self.popSet[ref].phenotype == phenotype:\n",
    "                    self.correctSet.append(ref) \n",
    "            #-------------------------------------------------------\n",
    "            # CONTINUOUS PHENOTYPE\n",
    "            #-------------------------------------------------------\n",
    "            else: \n",
    "                if float(phenotype) <= float(self.popSet[ref].phenotype[1]) and float(phenotype) >= float(self.popSet[ref].phenotype[0]):\n",
    "                    self.correctSet.append(ref)\n",
    "\n",
    "    \n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    # OTHER KEY METHODS\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    def addClassifierToPopulation(self, cl):\n",
    "        \"\"\" Adds a classifier to the set and increases the microPopSize value accordingly.\"\"\"\n",
    "        self.popSet.append(cl)\n",
    "        self.microPopSize += 1\n",
    "            \n",
    "\n",
    "    def updateSets(self, exploreIter):\n",
    "        \"\"\" Updates all relevant parameters in the current match and correct sets. \"\"\"\n",
    "        for ref in self.matchSet:\n",
    "            self.popSet[ref].updateExperience()    \n",
    "            if ref in self.correctSet:\n",
    "                self.popSet[ref].updateCorrect()\n",
    "\n",
    "            self.popSet[ref].updateAccuracy()\n",
    "            self.popSet[ref].updateFitness()\n",
    "\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    # OTHER METHODS\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    def setIterStamps(self, exploreIter):\n",
    "        \"\"\" Sets the time stamp of all classifiers in the set to the current time. The current time\n",
    "        is the number of exploration steps executed so far.  \"\"\"\n",
    "        for i in range(len(self.correctSet)):\n",
    "            ref = self.correctSet[i]\n",
    "            self.popSet[ref].updateTimeStamp(exploreIter)\n",
    "            \n",
    "     \n",
    "    def clearSets(self):\n",
    "        \"\"\" Clears out references in the match and correct sets for the next learning iteration. \"\"\"\n",
    "        self.matchSet = []\n",
    "        self.correctSet = []\n",
    "        \n",
    "            \n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    # EVALUTATION METHODS\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    def runPopAveEval(self, exploreIter):\n",
    "        \"\"\" Calculates some summary evaluations across the rule population including average generality. \"\"\"\n",
    "        genSum = 0\n",
    "        agedCount = 0\n",
    "        for cl in self.popSet:\n",
    "            genSum += ((cons.env.formatData.numAttributes - len(cl.condition)) / float(cons.env.formatData.numAttributes)) \n",
    "        if self.microPopSize == 0:\n",
    "            self.aveGenerality = 'NA'\n",
    "        else:\n",
    "            self.aveGenerality = genSum / float(self.microPopSize) \n",
    "\n",
    "        #-------------------------------------------------------\n",
    "        # CONTINUOUS PHENOTYPE\n",
    "        #-------------------------------------------------------\n",
    "        if not cons.env.formatData.discretePhenotype:\n",
    "            sumRuleRange = 0\n",
    "            for cl in self.popSet:\n",
    "                sumRuleRange += (cl.phenotype[1] - cl.phenotype[0])\n",
    "            phenotypeRange = cons.env.formatData.phenotypeList[1] - cons.env.formatData.phenotypeList[0]\n",
    "            self.avePhenotypeRange = (sumRuleRange / float(self.microPopSize)) / float(phenotypeRange)\n",
    "\n",
    "              \n",
    "    def getPopTrack(self, exploreIter, trackingFrequency):\n",
    "        \"\"\" Returns a formated output string to be printed to the Learn Track output file. \"\"\"\n",
    "        trackString = str(exploreIter)+ \"\\t\" + str(len(self.popSet)) + \"\\t\" + str(\"%.2f\" %self.aveGenerality)  +  \"\\n\"\n",
    "        if cons.env.formatData.discretePhenotype: #discrete phenotype\n",
    "            print((\"End Iteration: \" + str(exploreIter) + \"\\t PopSize: \" + str(len(self.popSet)) + \"\\t AveGen: \" + str(\"%.2f\" %self.aveGenerality)))\n",
    "            print(\"----------------------------------------------------------------------------------------------------------------\")\n",
    "        else: # continuous phenotype\n",
    "            print((\"End Iteration: \" + str(exploreIter) + \"\\t PopSize: \" + str(len(self.popSet)) + \"\\t AveGen: \" + str(\"%.2f\" %self.aveGenerality) + \"\\t PhenRange: \" +str(self.avePhenotypeRange)))\n",
    "            print(\"----------------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "        return trackString\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LCS class to run the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "hideCode": true
   },
   "outputs": [],
   "source": [
    "class eLCS:\n",
    "    def __init__(self):\n",
    "        \"\"\" Initializes the eLCS algorithm \"\"\"\n",
    "        print(\"eLCS: Initializing Algorithm...\")\n",
    "        #Global Parameters-------------------------------------------------------------------------------------\n",
    "        self.population = None          # The rule population (the 'solution/model' evolved by eLCS)\n",
    "        self.learnTrackOut = None       # Output file that will store tracking information during learning\n",
    "        \n",
    "        #-------------------------------------------------------\n",
    "        # POPULATION REBOOT - Begin eLCS learning from an existing saved rule population\n",
    "        #-------------------------------------------------------\n",
    "        if cons.doPopulationReboot:    \n",
    "            self.populationReboot()\n",
    "            \n",
    "        #-------------------------------------------------------\n",
    "        # NORMAL eLCS - Run eLCS from scratch on given data\n",
    "        #-------------------------------------------------------\n",
    "        else:\n",
    "            try:\n",
    "                self.learnTrackOut = open(cons.outFileName+'_LearnTrack.txt','w')     \n",
    "            except Exception as inst:\n",
    "                print(type(inst))\n",
    "                print(inst.args)\n",
    "                print(inst)\n",
    "                print('cannot open', cons.outFileName+'_LearnTrack.txt')\n",
    "                raise\n",
    "            else:\n",
    "                self.learnTrackOut.write(\"Explore_Iteration\\tPopSize\\tAveGenerality\\n\")#Explore_Iteration\\tPopSize\\tAccuracy_Estimate\\tAveGenerality\\tExpRules\\tTime(min)\\n\")\n",
    "            # Instantiate Population---------\n",
    "            self.population = ClassifierSet()\n",
    "            self.exploreIter = 0\n",
    "            self.correct  = [0.0 for i in range(cons.trackingFrequency)]\n",
    "            \n",
    "        #Run the eLCS algorithm-------------------------------------------------------------------------------\n",
    "        self.run_eLCS()\n",
    "\n",
    "\n",
    "    def run_eLCS(self):\n",
    "        \"\"\" Runs the initialized eLCS algorithm. \"\"\"\n",
    "        #--------------------------------------------------------------\n",
    "        print(\"Learning Checkpoints: \" +str(cons.learningCheckpoints))\n",
    "        print(\"Maximum Iterations: \" +str(cons.maxLearningIterations))\n",
    "        print(\"Beginning eLCS learning iterations.\")\n",
    "        print(\"------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "        #-------------------------------------------------------\n",
    "        # MAJOR LEARNING LOOP\n",
    "        #-------------------------------------------------------\n",
    "        while self.exploreIter < cons.maxLearningIterations: \n",
    "            \n",
    "            #-------------------------------------------------------\n",
    "            # GET NEW INSTANCE AND RUN A LEARNING ITERATION\n",
    "            #-------------------------------------------------------\n",
    "            state_phenotype = cons.env.getTrainInstance() \n",
    "            self.runIteration(state_phenotype, self.exploreIter)\n",
    "            \n",
    "            #-------------------------------------------------------\n",
    "            # TRACK PROGRESS\n",
    "            #-------------------------------------------------------\n",
    "            if (self.exploreIter%cons.trackingFrequency) == (cons.trackingFrequency - 1):\n",
    "                self.population.runPopAveEval(self.exploreIter) \n",
    "                self.learnTrackOut.write(self.population.getPopTrack(self.exploreIter+1,cons.trackingFrequency)) #Report learning progress to standard out and tracking file.\n",
    "            \n",
    "            #-------------------------------------------------------\n",
    "            # ADJUST MAJOR VALUES FOR NEXT ITERATION\n",
    "            #-------------------------------------------------------\n",
    "            self.exploreIter += 1       # Increment current learning iteration\n",
    "            cons.env.newInstance(True)  # Step to next instance in training set\n",
    "            \n",
    "        self.learnTrackOut.close()\n",
    "\n",
    "        print(\"eLCS Run Complete\")\n",
    "        \n",
    "        \n",
    "    def runIteration(self, state_phenotype, exploreIter):\n",
    "        \"\"\" Run a single eLCS learning iteration. \"\"\"\n",
    "        #-----------------------------------------------------------------------------------------------------------------------------------------\n",
    "        # FORM A MATCH SET - includes covering\n",
    "        #-----------------------------------------------------------------------------------------------------------------------------------------\n",
    "        self.population.makeMatchSet(state_phenotype, exploreIter)\n",
    "        #-----------------------------------------------------------------------------------------------------------------------------------------\n",
    "        # FORM A CORRECT SET\n",
    "        #-----------------------------------------------------------------------------------------------------------------------------------------\n",
    "        self.population.makeCorrectSet(state_phenotype[1])\n",
    "        #-----------------------------------------------------------------------------------------------------------------------------------------\n",
    "        # UPDATE PARAMETERS\n",
    "        #-----------------------------------------------------------------------------------------------------------------------------------------\n",
    "        self.population.updateSets(exploreIter)\n",
    "        self.population.clearSets() #Clears the match and correct sets for the next learning iteration\n",
    "        \n",
    "    \n",
    "    def populationReboot(self):\n",
    "        \"\"\" Manages the reformation of a previously saved eLCS classifier population. \"\"\"\n",
    "        #--------------------------------------------------------------------\n",
    "        try: #Re-open track learning file for continued tracking of progress.\n",
    "            self.learnTrackOut = open(cons.outFileName+'_LearnTrack.txt','a')     \n",
    "        except Exception as inst:\n",
    "            print(type(inst))\n",
    "            print(inst.args)\n",
    "            print(inst)\n",
    "            print('cannot open', cons.outFileName+'_LearnTrack.txt')\n",
    "            raise\n",
    "\n",
    "        #Extract last iteration from file name---------------------------------------------\n",
    "        temp = cons.popRebootPath.split('_')\n",
    "        iterRef = len(temp)-1\n",
    "        completedIterations = int(temp[iterRef])\n",
    "        print(\"Rebooting rule population after \" +str(completedIterations)+ \" iterations.\")\n",
    "        self.exploreIter = completedIterations-1\n",
    "        #for i in range(len(cons.learningCheckpoints)): ??? checkpoints not in demo 2\n",
    "            #cons.learningCheckpoints[i] += completedIterations\n",
    "        cons.maxLearningIterations += completedIterations\n",
    "\n",
    "        #Rebuild existing population from text file.--------\n",
    "        self.population = ClassifierSet(cons.popRebootPath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually RUN the eLCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "hideCode": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------\n",
      "Environment: Formatting Data... \n",
      "DataManagement: Loading Data... 6Multiplexer_Data_Complete.txt\n",
      "DataManagement: Phenotype Column Location = 6\n",
      "DataManagement: Number of Attributes = 6\n",
      "DataManagement: Number of Instances = 64\n",
      "DataManagement: Analyzing Phenotype...\n",
      "DataManagement: Phenotype Detected as Discrete.\n",
      "DataManagement: Detecting Classes...\n",
      "DataManagement: Following Classes Detected:['0', '1']\n",
      "Class: 0 count = 32\n",
      "Class: 1 count = 32\n",
      "DataManagement: Detecting Attributes...\n",
      "DataManagement: Identified 6 discrete and 0 continuous attributes.\n",
      "DataManagement: Characterizing Attributes...\n",
      "----------------------------------------------------------------------------\n",
      "eLCS: Initializing Algorithm...\n",
      "Learning Checkpoints: 64\n",
      "Maximum Iterations: 64\n",
      "Beginning eLCS learning iterations.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Current instance from dataset:  State = ['1', '1', '0', '0', '0', '1']  Phenotype = 1\n",
      "--------------------------------------------------------------------------------------\n",
      "Matching Classifiers:\n",
      "None found.\n",
      "Covering Activated:\n",
      "Condition: ['1', '#', '#', '#', '#', '#']  Phenotype: 1\n",
      "End Iteration: 1\t PopSize: 1\t AveGen: 0.83\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Current instance from dataset:  State = ['0', '1', '1', '1', '1', '0']  Phenotype = 1\n",
      "--------------------------------------------------------------------------------------\n",
      "Matching Classifiers:\n",
      "None found.\n",
      "Covering Activated:\n",
      "Condition: ['0', '#', '1', '1', '1', '#']  Phenotype: 1\n",
      "End Iteration: 2\t PopSize: 2\t AveGen: 0.58\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Current instance from dataset:  State = ['0', '0', '1', '0', '0', '0']  Phenotype = 1\n",
      "--------------------------------------------------------------------------------------\n",
      "Matching Classifiers:\n",
      "None found.\n",
      "Covering Activated:\n",
      "Condition: ['#', '0', '1', '0', '#', '#']  Phenotype: 1\n",
      "End Iteration: 3\t PopSize: 3\t AveGen: 0.56\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Current instance from dataset:  State = ['1', '0', '1', '0', '0', '1']  Phenotype = 0\n",
      "--------------------------------------------------------------------------------------\n",
      "Matching Classifiers:\n",
      "Condition: ['1', '#', '#', '#', '#', '#']  Phenotype: 1\n",
      "Condition: ['#', '0', '1', '0', '#', '#']  Phenotype: 1\n",
      "Covering Activated:\n",
      "Condition: ['1', '0', '1', '0', '0', '#']  Phenotype: 0\n",
      "End Iteration: 4\t PopSize: 4\t AveGen: 0.46\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Current instance from dataset:  State = ['0', '0', '1', '0', '1', '1']  Phenotype = 1\n",
      "--------------------------------------------------------------------------------------\n",
      "Matching Classifiers:\n",
      "Condition: ['#', '0', '1', '0', '#', '#']  Phenotype: 1\n",
      "End Iteration: 5\t PopSize: 4\t AveGen: 0.46\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Current instance from dataset:  State = ['0', '0', '0', '0', '0', '1']  Phenotype = 0\n",
      "--------------------------------------------------------------------------------------\n",
      "Matching Classifiers:\n",
      "None found.\n",
      "Covering Activated:\n",
      "Condition: ['#', '0', '#', '#', '#', '#']  Phenotype: 0\n",
      "End Iteration: 6\t PopSize: 5\t AveGen: 0.53\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Current instance from dataset:  State = ['1', '1', '1', '1', '0', '0']  Phenotype = 0\n",
      "--------------------------------------------------------------------------------------\n",
      "Matching Classifiers:\n",
      "Condition: ['1', '#', '#', '#', '#', '#']  Phenotype: 1\n",
      "Covering Activated:\n",
      "Condition: ['1', '#', '1', '1', '#', '#']  Phenotype: 0\n",
      "End Iteration: 7\t PopSize: 6\t AveGen: 0.53\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Current instance from dataset:  State = ['1', '0', '1', '1', '0', '1']  Phenotype = 0\n",
      "--------------------------------------------------------------------------------------\n",
      "Matching Classifiers:\n",
      "Condition: ['1', '#', '#', '#', '#', '#']  Phenotype: 1\n",
      "Condition: ['#', '0', '#', '#', '#', '#']  Phenotype: 0\n",
      "Condition: ['1', '#', '1', '1', '#', '#']  Phenotype: 0\n",
      "End Iteration: 8\t PopSize: 6\t AveGen: 0.53\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Current instance from dataset:  State = ['0', '0', '1', '1', '0', '0']  Phenotype = 1\n",
      "--------------------------------------------------------------------------------------\n",
      "Matching Classifiers:\n",
      "Condition: ['#', '0', '#', '#', '#', '#']  Phenotype: 0\n",
      "Covering Activated:\n",
      "Condition: ['0', '#', '1', '1', '0', '0']  Phenotype: 1\n",
      "End Iteration: 9\t PopSize: 7\t AveGen: 0.48\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Current instance from dataset:  State = ['0', '1', '1', '1', '0', '1']  Phenotype = 1\n",
      "--------------------------------------------------------------------------------------\n",
      "Matching Classifiers:\n",
      "None found.\n",
      "Covering Activated:\n",
      "Condition: ['#', '1', '1', '#', '0', '1']  Phenotype: 1\n",
      "End Iteration: 10\t PopSize: 8\t AveGen: 0.46\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Current instance from dataset:  State = ['1', '1', '0', '0', '1', '0']  Phenotype = 0\n",
      "--------------------------------------------------------------------------------------\n",
      "Matching Classifiers:\n",
      "Condition: ['1', '#', '#', '#', '#', '#']  Phenotype: 1\n",
      "Covering Activated:\n",
      "Condition: ['1', '#', '#', '#', '#', '#']  Phenotype: 0\n",
      "End Iteration: 11\t PopSize: 9\t AveGen: 0.50\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Current instance from dataset:  State = ['1', '1', '1', '0', '0', '0']  Phenotype = 0\n",
      "--------------------------------------------------------------------------------------\n",
      "Matching Classifiers:\n",
      "Condition: ['1', '#', '#', '#', '#', '#']  Phenotype: 1\n",
      "Condition: ['1', '#', '#', '#', '#', '#']  Phenotype: 0\n",
      "End Iteration: 12\t PopSize: 9\t AveGen: 0.50\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Current instance from dataset:  State = ['0', '1', '0', '1', '0', '0']  Phenotype = 1\n",
      "--------------------------------------------------------------------------------------\n",
      "Matching Classifiers:\n",
      "None found.\n",
      "Covering Activated:\n",
      "Condition: ['0', '#', '0', '#', '0', '0']  Phenotype: 1\n",
      "End Iteration: 13\t PopSize: 10\t AveGen: 0.48\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Current instance from dataset:  State = ['0', '1', '1', '0', '0', '0']  Phenotype = 0\n",
      "--------------------------------------------------------------------------------------\n",
      "Matching Classifiers:\n",
      "None found.\n",
      "Covering Activated:\n",
      "Condition: ['#', '1', '#', '#', '#', '0']  Phenotype: 0\n",
      "End Iteration: 14\t PopSize: 11\t AveGen: 0.50\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Current instance from dataset:  State = ['0', '0', '1', '1', '1', '1']  Phenotype = 1\n",
      "--------------------------------------------------------------------------------------\n",
      "Matching Classifiers:\n",
      "Condition: ['0', '#', '1', '1', '1', '#']  Phenotype: 1\n",
      "Condition: ['#', '0', '#', '#', '#', '#']  Phenotype: 0\n",
      "End Iteration: 15\t PopSize: 11\t AveGen: 0.50\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Current instance from dataset:  State = ['1', '1', '0', '1', '1', '0']  Phenotype = 0\n",
      "--------------------------------------------------------------------------------------\n",
      "Matching Classifiers:\n",
      "Condition: ['1', '#', '#', '#', '#', '#']  Phenotype: 1\n",
      "Condition: ['1', '#', '#', '#', '#', '#']  Phenotype: 0\n",
      "Condition: ['#', '1', '#', '#', '#', '0']  Phenotype: 0\n",
      "End Iteration: 16\t PopSize: 11\t AveGen: 0.50\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Current instance from dataset:  State = ['1', '1', '1', '0', '1', '0']  Phenotype = 0\n",
      "--------------------------------------------------------------------------------------\n",
      "Matching Classifiers:\n",
      "Condition: ['1', '#', '#', '#', '#', '#']  Phenotype: 1\n",
      "Condition: ['1', '#', '#', '#', '#', '#']  Phenotype: 0\n",
      "Condition: ['#', '1', '#', '#', '#', '0']  Phenotype: 0\n",
      "End Iteration: 17\t PopSize: 11\t AveGen: 0.50\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Current instance from dataset:  State = ['1', '1', '1', '1', '1', '1']  Phenotype = 1\n",
      "--------------------------------------------------------------------------------------\n",
      "Matching Classifiers:\n",
      "Condition: ['1', '#', '#', '#', '#', '#']  Phenotype: 1\n",
      "Condition: ['1', '#', '1', '1', '#', '#']  Phenotype: 0\n",
      "Condition: ['1', '#', '#', '#', '#', '#']  Phenotype: 0\n",
      "End Iteration: 18\t PopSize: 11\t AveGen: 0.50\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Current instance from dataset:  State = ['1', '1', '0', '1', '0', '1']  Phenotype = 1\n",
      "--------------------------------------------------------------------------------------\n",
      "Matching Classifiers:\n",
      "Condition: ['1', '#', '#', '#', '#', '#']  Phenotype: 1\n",
      "Condition: ['1', '#', '#', '#', '#', '#']  Phenotype: 0\n",
      "End Iteration: 19\t PopSize: 11\t AveGen: 0.50\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Current instance from dataset:  State = ['1', '0', '1', '0', '0', '0']  Phenotype = 0\n",
      "--------------------------------------------------------------------------------------\n",
      "Matching Classifiers:\n",
      "Condition: ['1', '#', '#', '#', '#', '#']  Phenotype: 1\n",
      "Condition: ['#', '0', '1', '0', '#', '#']  Phenotype: 1\n",
      "Condition: ['1', '0', '1', '0', '0', '#']  Phenotype: 0\n",
      "Condition: ['#', '0', '#', '#', '#', '#']  Phenotype: 0\n",
      "Condition: ['1', '#', '#', '#', '#', '#']  Phenotype: 0\n",
      "End Iteration: 20\t PopSize: 11\t AveGen: 0.50\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Current instance from dataset:  State = ['0', '0', '1', '1', '1', '0']  Phenotype = 1\n",
      "--------------------------------------------------------------------------------------\n",
      "Matching Classifiers:\n",
      "Condition: ['0', '#', '1', '1', '1', '#']  Phenotype: 1\n",
      "Condition: ['#', '0', '#', '#', '#', '#']  Phenotype: 0\n",
      "End Iteration: 21\t PopSize: 11\t AveGen: 0.50\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Current instance from dataset:  State = ['1', '1', '0', '1', '1', '1']  Phenotype = 1\n",
      "--------------------------------------------------------------------------------------\n",
      "Matching Classifiers:\n",
      "Condition: ['1', '#', '#', '#', '#', '#']  Phenotype: 1\n",
      "Condition: ['1', '#', '#', '#', '#', '#']  Phenotype: 0\n",
      "End Iteration: 22\t PopSize: 11\t AveGen: 0.50\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Current instance from dataset:  State = ['0', '0', '0', '0', '1', '1']  Phenotype = 0\n",
      "--------------------------------------------------------------------------------------\n",
      "Matching Classifiers:\n",
      "Condition: ['#', '0', '#', '#', '#', '#']  Phenotype: 0\n",
      "End Iteration: 23\t PopSize: 11\t AveGen: 0.50\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Current instance from dataset:  State = ['0', '1', '0', '1', '1', '1']  Phenotype = 1\n",
      "--------------------------------------------------------------------------------------\n",
      "Matching Classifiers:\n",
      "None found.\n",
      "Covering Activated:\n",
      "Condition: ['#', '1', '0', '1', '#', '#']  Phenotype: 1\n",
      "End Iteration: 24\t PopSize: 12\t AveGen: 0.50\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Current instance from dataset:  State = ['0', '0', '1', '1', '0', '1']  Phenotype = 1\n",
      "--------------------------------------------------------------------------------------\n",
      "Matching Classifiers:\n",
      "Condition: ['#', '0', '#', '#', '#', '#']  Phenotype: 0\n",
      "Covering Activated:\n",
      "Condition: ['#', '0', '#', '1', '#', '1']  Phenotype: 1\n",
      "End Iteration: 25\t PopSize: 13\t AveGen: 0.50\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Current instance from dataset:  State = ['1', '0', '1', '1', '0', '0']  Phenotype = 0\n",
      "--------------------------------------------------------------------------------------\n",
      "Matching Classifiers:\n",
      "Condition: ['1', '#', '#', '#', '#', '#']  Phenotype: 1\n",
      "Condition: ['#', '0', '#', '#', '#', '#']  Phenotype: 0\n",
      "Condition: ['1', '#', '1', '1', '#', '#']  Phenotype: 0\n",
      "Condition: ['1', '#', '#', '#', '#', '#']  Phenotype: 0\n",
      "End Iteration: 26\t PopSize: 13\t AveGen: 0.50\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Current instance from dataset:  State = ['1', '0', '1', '0', '1', '0']  Phenotype = 1\n",
      "--------------------------------------------------------------------------------------\n",
      "Matching Classifiers:\n",
      "Condition: ['1', '#', '#', '#', '#', '#']  Phenotype: 1\n",
      "Condition: ['#', '0', '1', '0', '#', '#']  Phenotype: 1\n",
      "Condition: ['#', '0', '#', '#', '#', '#']  Phenotype: 0\n",
      "Condition: ['1', '#', '#', '#', '#', '#']  Phenotype: 0\n",
      "End Iteration: 27\t PopSize: 13\t AveGen: 0.50\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Current instance from dataset:  State = ['0', '1', '1', '1', '1', '1']  Phenotype = 1\n",
      "--------------------------------------------------------------------------------------\n",
      "Matching Classifiers:\n",
      "Condition: ['0', '#', '1', '1', '1', '#']  Phenotype: 1\n",
      "End Iteration: 28\t PopSize: 13\t AveGen: 0.50\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Current instance from dataset:  State = ['1', '0', '1', '1', '1', '0']  Phenotype = 1\n",
      "--------------------------------------------------------------------------------------\n",
      "Matching Classifiers:\n",
      "Condition: ['1', '#', '#', '#', '#', '#']  Phenotype: 1\n",
      "Condition: ['#', '0', '#', '#', '#', '#']  Phenotype: 0\n",
      "Condition: ['1', '#', '1', '1', '#', '#']  Phenotype: 0\n",
      "Condition: ['1', '#', '#', '#', '#', '#']  Phenotype: 0\n",
      "End Iteration: 29\t PopSize: 13\t AveGen: 0.50\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Current instance from dataset:  State = ['1', '1', '0', '1', '0', '0']  Phenotype = 0\n",
      "--------------------------------------------------------------------------------------\n",
      "Matching Classifiers:\n",
      "Condition: ['1', '#', '#', '#', '#', '#']  Phenotype: 1\n",
      "Condition: ['1', '#', '#', '#', '#', '#']  Phenotype: 0\n",
      "Condition: ['#', '1', '#', '#', '#', '0']  Phenotype: 0\n",
      "Condition: ['#', '1', '0', '1', '#', '#']  Phenotype: 1\n",
      "End Iteration: 30\t PopSize: 13\t AveGen: 0.50\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Current instance from dataset:  State = ['0', '1', '0', '1', '1', '0']  Phenotype = 1\n",
      "--------------------------------------------------------------------------------------\n",
      "Matching Classifiers:\n",
      "Condition: ['#', '1', '#', '#', '#', '0']  Phenotype: 0\n",
      "Condition: ['#', '1', '0', '1', '#', '#']  Phenotype: 1\n",
      "End Iteration: 31\t PopSize: 13\t AveGen: 0.50\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Current instance from dataset:  State = ['0', '0', '0', '0', '0', '0']  Phenotype = 0\n",
      "--------------------------------------------------------------------------------------\n",
      "Matching Classifiers:\n",
      "Condition: ['#', '0', '#', '#', '#', '#']  Phenotype: 0\n",
      "Condition: ['0', '#', '0', '#', '0', '0']  Phenotype: 1\n",
      "End Iteration: 32\t PopSize: 13\t AveGen: 0.50\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Current instance from dataset:  State = ['1', '1', '1', '1', '1', '0']  Phenotype = 0\n",
      "--------------------------------------------------------------------------------------\n",
      "Matching Classifiers:\n",
      "Condition: ['1', '#', '#', '#', '#', '#']  Phenotype: 1\n",
      "Condition: ['1', '#', '1', '1', '#', '#']  Phenotype: 0\n",
      "Condition: ['1', '#', '#', '#', '#', '#']  Phenotype: 0\n",
      "Condition: ['#', '1', '#', '#', '#', '0']  Phenotype: 0\n",
      "End Iteration: 33\t PopSize: 13\t AveGen: 0.50\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Current instance from dataset:  State = ['0', '1', '0', '0', '1', '0']  Phenotype = 0\n",
      "--------------------------------------------------------------------------------------\n",
      "Matching Classifiers:\n",
      "Condition: ['#', '1', '#', '#', '#', '0']  Phenotype: 0\n",
      "End Iteration: 34\t PopSize: 13\t AveGen: 0.50\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Current instance from dataset:  State = ['1', '0', '1', '1', '1', '1']  Phenotype = 1\n",
      "--------------------------------------------------------------------------------------\n",
      "Matching Classifiers:\n",
      "Condition: ['1', '#', '#', '#', '#', '#']  Phenotype: 1\n",
      "Condition: ['#', '0', '#', '#', '#', '#']  Phenotype: 0\n",
      "Condition: ['1', '#', '1', '1', '#', '#']  Phenotype: 0\n",
      "Condition: ['1', '#', '#', '#', '#', '#']  Phenotype: 0\n",
      "Condition: ['#', '0', '#', '1', '#', '1']  Phenotype: 1\n",
      "End Iteration: 35\t PopSize: 13\t AveGen: 0.50\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Current instance from dataset:  State = ['1', '0', '0', '0', '1', '0']  Phenotype = 1\n",
      "--------------------------------------------------------------------------------------\n",
      "Matching Classifiers:\n",
      "Condition: ['1', '#', '#', '#', '#', '#']  Phenotype: 1\n",
      "Condition: ['#', '0', '#', '#', '#', '#']  Phenotype: 0\n",
      "Condition: ['1', '#', '#', '#', '#', '#']  Phenotype: 0\n",
      "End Iteration: 36\t PopSize: 13\t AveGen: 0.50\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Current instance from dataset:  State = ['0', '1', '1', '1', '0', '0']  Phenotype = 1\n",
      "--------------------------------------------------------------------------------------\n",
      "Matching Classifiers:\n",
      "Condition: ['0', '#', '1', '1', '0', '0']  Phenotype: 1\n",
      "Condition: ['#', '1', '#', '#', '#', '0']  Phenotype: 0\n",
      "End Iteration: 37\t PopSize: 13\t AveGen: 0.50\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Current instance from dataset:  State = ['0', '1', '0', '0', '0', '1']  Phenotype = 0\n",
      "--------------------------------------------------------------------------------------\n",
      "Matching Classifiers:\n",
      "None found.\n",
      "Covering Activated:\n",
      "Condition: ['#', '#', '#', '0', '0', '1']  Phenotype: 0\n",
      "End Iteration: 38\t PopSize: 14\t AveGen: 0.50\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Current instance from dataset:  State = ['0', '0', '0', '0', '1', '0']  Phenotype = 0\n",
      "--------------------------------------------------------------------------------------\n",
      "Matching Classifiers:\n",
      "Condition: ['#', '0', '#', '#', '#', '#']  Phenotype: 0\n",
      "End Iteration: 39\t PopSize: 14\t AveGen: 0.50\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Current instance from dataset:  State = ['1', '0', '0', '1', '0', '0']  Phenotype = 0\n",
      "--------------------------------------------------------------------------------------\n",
      "Matching Classifiers:\n",
      "Condition: ['1', '#', '#', '#', '#', '#']  Phenotype: 1\n",
      "Condition: ['#', '0', '#', '#', '#', '#']  Phenotype: 0\n",
      "Condition: ['1', '#', '#', '#', '#', '#']  Phenotype: 0\n",
      "End Iteration: 40\t PopSize: 14\t AveGen: 0.50\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Current instance from dataset:  State = ['1', '0', '0', '1', '1', '1']  Phenotype = 1\n",
      "--------------------------------------------------------------------------------------\n",
      "Matching Classifiers:\n",
      "Condition: ['1', '#', '#', '#', '#', '#']  Phenotype: 1\n",
      "Condition: ['#', '0', '#', '#', '#', '#']  Phenotype: 0\n",
      "Condition: ['1', '#', '#', '#', '#', '#']  Phenotype: 0\n",
      "Condition: ['#', '0', '#', '1', '#', '1']  Phenotype: 1\n",
      "End Iteration: 41\t PopSize: 14\t AveGen: 0.50\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Current instance from dataset:  State = ['1', '1', '0', '0', '0', '0']  Phenotype = 0\n",
      "--------------------------------------------------------------------------------------\n",
      "Matching Classifiers:\n",
      "Condition: ['1', '#', '#', '#', '#', '#']  Phenotype: 1\n",
      "Condition: ['1', '#', '#', '#', '#', '#']  Phenotype: 0\n",
      "Condition: ['#', '1', '#', '#', '#', '0']  Phenotype: 0\n",
      "End Iteration: 42\t PopSize: 14\t AveGen: 0.50\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Current instance from dataset:  State = ['0', '0', '1', '0', '1', '0']  Phenotype = 1\n",
      "--------------------------------------------------------------------------------------\n",
      "Matching Classifiers:\n",
      "Condition: ['#', '0', '1', '0', '#', '#']  Phenotype: 1\n",
      "Condition: ['#', '0', '#', '#', '#', '#']  Phenotype: 0\n",
      "End Iteration: 43\t PopSize: 14\t AveGen: 0.50\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Current instance from dataset:  State = ['1', '0', '0', '0', '0', '1']  Phenotype = 0\n",
      "--------------------------------------------------------------------------------------\n",
      "Matching Classifiers:\n",
      "Condition: ['1', '#', '#', '#', '#', '#']  Phenotype: 1\n",
      "Condition: ['#', '0', '#', '#', '#', '#']  Phenotype: 0\n",
      "Condition: ['1', '#', '#', '#', '#', '#']  Phenotype: 0\n",
      "Condition: ['#', '#', '#', '0', '0', '1']  Phenotype: 0\n",
      "End Iteration: 44\t PopSize: 14\t AveGen: 0.50\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Current instance from dataset:  State = ['1', '0', '1', '0', '1', '1']  Phenotype = 1\n",
      "--------------------------------------------------------------------------------------\n",
      "Matching Classifiers:\n",
      "Condition: ['1', '#', '#', '#', '#', '#']  Phenotype: 1\n",
      "Condition: ['#', '0', '1', '0', '#', '#']  Phenotype: 1\n",
      "Condition: ['#', '0', '#', '#', '#', '#']  Phenotype: 0\n",
      "Condition: ['1', '#', '#', '#', '#', '#']  Phenotype: 0\n",
      "End Iteration: 45\t PopSize: 14\t AveGen: 0.50\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Current instance from dataset:  State = ['0', '0', '1', '0', '0', '1']  Phenotype = 1\n",
      "--------------------------------------------------------------------------------------\n",
      "Matching Classifiers:\n",
      "Condition: ['#', '0', '1', '0', '#', '#']  Phenotype: 1\n",
      "Condition: ['#', '0', '#', '#', '#', '#']  Phenotype: 0\n",
      "Condition: ['#', '#', '#', '0', '0', '1']  Phenotype: 0\n",
      "End Iteration: 46\t PopSize: 14\t AveGen: 0.50\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Current instance from dataset:  State = ['0', '1', '0', '0', '0', '0']  Phenotype = 0\n",
      "--------------------------------------------------------------------------------------\n",
      "Matching Classifiers:\n",
      "Condition: ['0', '#', '0', '#', '0', '0']  Phenotype: 1\n",
      "Condition: ['#', '1', '#', '#', '#', '0']  Phenotype: 0\n",
      "End Iteration: 47\t PopSize: 14\t AveGen: 0.50\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Current instance from dataset:  State = ['0', '1', '1', '0', '1', '1']  Phenotype = 0\n",
      "--------------------------------------------------------------------------------------\n",
      "Matching Classifiers:\n",
      "None found.\n",
      "Covering Activated:\n",
      "Condition: ['#', '#', '#', '0', '1', '#']  Phenotype: 0\n",
      "End Iteration: 48\t PopSize: 15\t AveGen: 0.51\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Current instance from dataset:  State = ['0', '1', '0', '0', '1', '1']  Phenotype = 0\n",
      "--------------------------------------------------------------------------------------\n",
      "Matching Classifiers:\n",
      "Condition: ['#', '#', '#', '0', '1', '#']  Phenotype: 0\n",
      "End Iteration: 49\t PopSize: 15\t AveGen: 0.51\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Current instance from dataset:  State = ['0', '1', '0', '1', '0', '1']  Phenotype = 1\n",
      "--------------------------------------------------------------------------------------\n",
      "Matching Classifiers:\n",
      "Condition: ['#', '1', '0', '1', '#', '#']  Phenotype: 1\n",
      "End Iteration: 50\t PopSize: 15\t AveGen: 0.51\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Current instance from dataset:  State = ['0', '0', '0', '1', '1', '1']  Phenotype = 0\n",
      "--------------------------------------------------------------------------------------\n",
      "Matching Classifiers:\n",
      "Condition: ['#', '0', '#', '#', '#', '#']  Phenotype: 0\n",
      "Condition: ['#', '0', '#', '1', '#', '1']  Phenotype: 1\n",
      "End Iteration: 51\t PopSize: 15\t AveGen: 0.51\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Current instance from dataset:  State = ['1', '0', '0', '0', '0', '0']  Phenotype = 0\n",
      "--------------------------------------------------------------------------------------\n",
      "Matching Classifiers:\n",
      "Condition: ['1', '#', '#', '#', '#', '#']  Phenotype: 1\n",
      "Condition: ['#', '0', '#', '#', '#', '#']  Phenotype: 0\n",
      "Condition: ['1', '#', '#', '#', '#', '#']  Phenotype: 0\n",
      "End Iteration: 52\t PopSize: 15\t AveGen: 0.51\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Current instance from dataset:  State = ['1', '1', '1', '0', '1', '1']  Phenotype = 1\n",
      "--------------------------------------------------------------------------------------\n",
      "Matching Classifiers:\n",
      "Condition: ['1', '#', '#', '#', '#', '#']  Phenotype: 1\n",
      "Condition: ['1', '#', '#', '#', '#', '#']  Phenotype: 0\n",
      "Condition: ['#', '#', '#', '0', '1', '#']  Phenotype: 0\n",
      "End Iteration: 53\t PopSize: 15\t AveGen: 0.51\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Current instance from dataset:  State = ['1', '1', '0', '0', '1', '1']  Phenotype = 1\n",
      "--------------------------------------------------------------------------------------\n",
      "Matching Classifiers:\n",
      "Condition: ['1', '#', '#', '#', '#', '#']  Phenotype: 1\n",
      "Condition: ['1', '#', '#', '#', '#', '#']  Phenotype: 0\n",
      "Condition: ['#', '#', '#', '0', '1', '#']  Phenotype: 0\n",
      "End Iteration: 54\t PopSize: 15\t AveGen: 0.51\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Current instance from dataset:  State = ['0', '0', '0', '1', '0', '0']  Phenotype = 0\n",
      "--------------------------------------------------------------------------------------\n",
      "Matching Classifiers:\n",
      "Condition: ['#', '0', '#', '#', '#', '#']  Phenotype: 0\n",
      "Condition: ['0', '#', '0', '#', '0', '0']  Phenotype: 1\n",
      "End Iteration: 55\t PopSize: 15\t AveGen: 0.51\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Current instance from dataset:  State = ['1', '0', '0', '1', '1', '0']  Phenotype = 1\n",
      "--------------------------------------------------------------------------------------\n",
      "Matching Classifiers:\n",
      "Condition: ['1', '#', '#', '#', '#', '#']  Phenotype: 1\n",
      "Condition: ['#', '0', '#', '#', '#', '#']  Phenotype: 0\n",
      "Condition: ['1', '#', '#', '#', '#', '#']  Phenotype: 0\n",
      "End Iteration: 56\t PopSize: 15\t AveGen: 0.51\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Current instance from dataset:  State = ['0', '1', '1', '0', '0', '1']  Phenotype = 0\n",
      "--------------------------------------------------------------------------------------\n",
      "Matching Classifiers:\n",
      "Condition: ['#', '1', '1', '#', '0', '1']  Phenotype: 1\n",
      "Condition: ['#', '#', '#', '0', '0', '1']  Phenotype: 0\n",
      "End Iteration: 57\t PopSize: 15\t AveGen: 0.51\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Current instance from dataset:  State = ['1', '0', '0', '0', '1', '1']  Phenotype = 1\n",
      "--------------------------------------------------------------------------------------\n",
      "Matching Classifiers:\n",
      "Condition: ['1', '#', '#', '#', '#', '#']  Phenotype: 1\n",
      "Condition: ['#', '0', '#', '#', '#', '#']  Phenotype: 0\n",
      "Condition: ['1', '#', '#', '#', '#', '#']  Phenotype: 0\n",
      "Condition: ['#', '#', '#', '0', '1', '#']  Phenotype: 0\n",
      "End Iteration: 58\t PopSize: 15\t AveGen: 0.51\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Current instance from dataset:  State = ['0', '0', '0', '1', '0', '1']  Phenotype = 0\n",
      "--------------------------------------------------------------------------------------\n",
      "Matching Classifiers:\n",
      "Condition: ['#', '0', '#', '#', '#', '#']  Phenotype: 0\n",
      "Condition: ['#', '0', '#', '1', '#', '1']  Phenotype: 1\n",
      "End Iteration: 59\t PopSize: 15\t AveGen: 0.51\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Current instance from dataset:  State = ['1', '0', '0', '1', '0', '1']  Phenotype = 0\n",
      "--------------------------------------------------------------------------------------\n",
      "Matching Classifiers:\n",
      "Condition: ['1', '#', '#', '#', '#', '#']  Phenotype: 1\n",
      "Condition: ['#', '0', '#', '#', '#', '#']  Phenotype: 0\n",
      "Condition: ['1', '#', '#', '#', '#', '#']  Phenotype: 0\n",
      "Condition: ['#', '0', '#', '1', '#', '1']  Phenotype: 1\n",
      "End Iteration: 60\t PopSize: 15\t AveGen: 0.51\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Current instance from dataset:  State = ['0', '1', '1', '0', '1', '0']  Phenotype = 0\n",
      "--------------------------------------------------------------------------------------\n",
      "Matching Classifiers:\n",
      "Condition: ['#', '1', '#', '#', '#', '0']  Phenotype: 0\n",
      "Condition: ['#', '#', '#', '0', '1', '#']  Phenotype: 0\n",
      "End Iteration: 61\t PopSize: 15\t AveGen: 0.51\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Current instance from dataset:  State = ['1', '1', '1', '1', '0', '1']  Phenotype = 1\n",
      "--------------------------------------------------------------------------------------\n",
      "Matching Classifiers:\n",
      "Condition: ['1', '#', '#', '#', '#', '#']  Phenotype: 1\n",
      "Condition: ['1', '#', '1', '1', '#', '#']  Phenotype: 0\n",
      "Condition: ['#', '1', '1', '#', '0', '1']  Phenotype: 1\n",
      "Condition: ['1', '#', '#', '#', '#', '#']  Phenotype: 0\n",
      "End Iteration: 62\t PopSize: 15\t AveGen: 0.51\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Current instance from dataset:  State = ['1', '1', '1', '0', '0', '1']  Phenotype = 1\n",
      "--------------------------------------------------------------------------------------\n",
      "Matching Classifiers:\n",
      "Condition: ['1', '#', '#', '#', '#', '#']  Phenotype: 1\n",
      "Condition: ['#', '1', '1', '#', '0', '1']  Phenotype: 1\n",
      "Condition: ['1', '#', '#', '#', '#', '#']  Phenotype: 0\n",
      "Condition: ['#', '#', '#', '0', '0', '1']  Phenotype: 0\n",
      "End Iteration: 63\t PopSize: 15\t AveGen: 0.51\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "Current instance from dataset:  State = ['0', '0', '0', '1', '1', '0']  Phenotype = 0\n",
      "--------------------------------------------------------------------------------------\n",
      "Matching Classifiers:\n",
      "Condition: ['#', '0', '#', '#', '#', '#']  Phenotype: 0\n",
      "End Iteration: 64\t PopSize: 15\t AveGen: 0.51\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "eLCS Run Complete\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.eLCS at 0x1fc87141bb0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Initialize the 'Environment' module which manages the data presented to the algorithm.  While e-LCS learns iteratively (one inistance at a time\n",
    "env = Offline_Environment()\n",
    "cons.referenceEnv(env) #Passes the environment to 'Constants' (cons) so that it can be easily accessed from anywhere within the code.\n",
    "cons.parseIterations() #Identify the maximum number of learning iterations as well as evaluation checkpoints.\n",
    "\n",
    "#Run the e-LCS algorithm.\n",
    "eLCS()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot diagram of Average population and Pop size per generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "hideCode": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:       \n",
    "    datasetList = [] #np.array([])\n",
    "    arraylist = np.array([])\n",
    "    headerList = np.array([])\n",
    "    ds = open(cons.outFileName+'_LearnTrack.txt','r')  \n",
    "except Exception as inst:\n",
    "    print(type(inst))\n",
    "    print(inst.args)\n",
    "    print(inst)\n",
    "    print('cannot open', cons.outFileName+'_LearnTrack.txt')\n",
    "    raise\n",
    "else:\n",
    "    headerList = ds.readline().rstrip('\\n').split('\\t')   #strip off first row\n",
    "    for line in ds:\n",
    "        lineList = line.strip('\\n').split('\\t')\n",
    "        arraylist = [float(i) for i in lineList]\n",
    "        datasetList.append(arraylist)\n",
    "    ds.close()  \n",
    "\n",
    "\n",
    "#maybe easier to reshape then use [:,0] but have not tried...\n",
    "a = [row[0] for row in datasetList]   \n",
    "b = [row[1] for row in datasetList]  \n",
    "c = [row[2] for row in datasetList]  \n",
    "    \n",
    "# Create plots with pre-defined labels.\n",
    "plt.plot(a, b, 'k--', label=headerList[1] )\n",
    "plt.plot(a, c, 'k:', label=headerList[2])\n",
    "\n",
    "\n",
    "plt.xlabel(headerList[0])\n",
    "legend = plt.legend(loc='center', shadow=True, fontsize='large')\n",
    "\n",
    "# Put a nicer background color on the legend.\n",
    "legend.get_frame().set_facecolor('#D2D2D2')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Hide code",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
